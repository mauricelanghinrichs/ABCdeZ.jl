<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>ABCdeZ.jl · ABCdeZ.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>ABCdeZ.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>ABCdeZ.jl</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Minimal-example"><span>Minimal example</span></a></li><li><a class="tocitem" href="#Inference-by-abcdesmc!"><span>Inference by abcdesmc!</span></a></li><li><a class="tocitem" href="#Inference-by-abcdemc!"><span>Inference by abcdemc!</span></a></li><li><a class="tocitem" href="#Distributions-and-Priors"><span>Distributions and Priors</span></a></li><li><a class="tocitem" href="#Various-notes"><span>Various notes</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>ABCdeZ.jl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>ABCdeZ.jl</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/main/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ABCdeZ.jl"><a class="docs-heading-anchor" href="#ABCdeZ.jl">ABCdeZ.jl</a><a id="ABCdeZ.jl-1"></a><a class="docs-heading-anchor-permalink" href="#ABCdeZ.jl" title="Permalink"></a></h1><p>Approximate Bayesian Computation (<strong>ABC</strong>) with differential evolution (<strong>de</strong>) moves and model evidence (<strong>Z</strong>) estimates.</p><p>ABCdeZ.jl offers Bayesian parameter estimation and model comparison/selection for inference problems with an intractable likelihood. Models only need to be simulated (instead of calculating the likelihood). In this documentation you will find everything to get started.</p><ul><li><a href="#ABCdeZ.jl">ABCdeZ.jl</a></li><li class="no-marker"><ul><li><a href="#Introduction">Introduction</a></li><li><a href="#Minimal-example">Minimal example</a></li><li><a href="#Inference-by-abcdesmc!">Inference by abcdesmc!</a></li><li><a href="#Inference-by-abcdemc!">Inference by abcdemc!</a></li><li><a href="#Distributions-and-Priors">Distributions and Priors</a></li><li><a href="#Various-notes">Various notes</a></li><li><a href="#References">References</a></li><li><a href="#Index">Index</a></li></ul></li></ul><p>ABCdeZ.jl was developed <a href="https://www.dkfz.de/en/modellierung-biologischer-systeme/">@TSB</a> by <a href="mailto:m.langhinrichs@icloud.com">Maurice Langhinrichs</a> and Nils Becker. This work is based on many people&#39;s previous achievements, particular some part of the code base was adapted from <a href="https://github.com/francescoalemanno/KissABC.jl">KissABC.jl</a>; please find a a complete list of references <a href="#References">below</a>.</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><ul><li>two example files for both alg. ? or one extended minimal example (also changing   script in examples...)</li><li>describe briefly: demc greedy version (biased before  completion but fast), desmc (accurate, a bit slower, but also  evidence estimate (up to (final) kernel norm))</li><li>link to all the caveats of ABC-based evidence values</li></ul><p>Here&#39;s some inline maths: <span>$\sqrt[n]{1 + x + x^2 + \ldots}$</span>.</p><p>To write a system of equations, use the <code>aligned</code> environment:</p><p class="math-container">\[\begin{aligned}
\nabla\cdot\mathbf{E}  &amp;= 4 \pi \rho \\
\nabla\cdot\mathbf{B}  &amp;= 0 \\
\nabla\times\mathbf{E} &amp;= - \frac{1}{c} \frac{\partial\mathbf{B}}{\partial t} \\
\nabla\times\mathbf{B} &amp;= - \frac{1}{c} \left(4 \pi \mathbf{J} + \frac{\partial\mathbf{E}}{\partial t} \right)
\end{aligned}\]</p><p>These are Maxwell&#39;s equations.</p><h2 id="Minimal-example"><a class="docs-heading-anchor" href="#Minimal-example">Minimal example</a><a id="Minimal-example-1"></a><a class="docs-heading-anchor-permalink" href="#Minimal-example" title="Permalink"></a></h2><p>Here we will use ABCdeZ.jl to infer the model evidences and posterior distributions within a simple toy example. The models have a single parameter <span>$θ$</span> that is, <em>a priori</em>, normally distributed (prior). After seeing one single data point, we obtain an updated posterior knowledge. To obtain model evidences, next to the posterior samples, we will use the <a href="#Inference-by-abcdesmc!"><code>abcdesmc!</code></a> method; for posterior samples only one may also use <code>abcdemc!</code> with a very similar syntax as seen in an <a href="#Inference-by-abcdemc!">code example</a>.</p><p>ABCdeZ.jl (as ABC in general) requires model simulations (for samples of <span>$θ$</span>) only, and not the likelihood values (at these <span>$θ$</span>). However, in this simple example the likelihood is available and chosen in a way (also Normal) that the prior is conjugate, and the exact posterior distributions and evidences are known analytically. We will compare the inferences made by ABCdeZ.jl with the analytical counterparts.</p><p>We load the required packages, set the single data point and the target <span>$ϵ$</span> for the ABC runs.</p><pre><code class="language-julia hljs">using ABCdeZ
using Distributions

### data
data = 3

### ABC target ϵ (maximum distance)
ϵ = 0.3</code></pre><p>Then we set up the inference of a first model. The normal prior is specified via <code>Distributions</code> (for more see &quot;Prior&quot; box below). Note that the model is solely specified by a  random simulation for a given <span>$θ$</span>. The distance function here simply reports the absolute distance between the random model output and the single data point (see <a href="#Features-for-the-distance-methods">here</a> for additional features in the distance function).</p><pre><code class="language-julia hljs">### model 1 inference
σ₁² = 10
prior1 = Normal(0, sqrt(σ₁²))

# model simulation (to replace likelihood)
model1(θ) = rand(Normal(θ, 1))

# distance function between model and data
dist1!(θ, ve) = abs(model1(θ)-data), nothing</code></pre><p>With the following line we run the <code>abcdesmc!</code> method of ABCdeZ.jl. The inference result is stored in <code>r1</code>.</p><pre><code class="language-julia hljs">### ABC run
# run the smc method for model 1
r1 = abcdesmc!(prior1, dist1!, ϵ, nothing, 
                    nparticles=1000, parallel=true)</code></pre><p>From the result <code>r1</code> we can read out the posterior samples (important: weighted by <code>Wns</code>,  see box &quot;Posterior sample weights&quot; <a href="#Inference-by-abcdesmc!">here</a>) and the estimated model evidence for model 1 (transforming back from log-scale).</p><pre><code class="language-julia hljs">### process results
# posterior parameters
posterior1 = [t[1] for t in r1.P[r1.Wns .&gt; 0.0]]

# model evidence (logZ is the logarithmic evidence)
evidence1 = exp(r1.logZ)</code></pre><p>Plotting the <code>posterior1</code> samples as a histogram, one can see the gained knowledge from the  prior just by the single data point (Figure below, left panel). The samples also match the analytical posterior, available in this simple example.</p><img src="./assets/abcdez_min_ex_post.png" width="566"><p>To demonstrate model comparison enabled by ABCdeZ.jl, we now repeat the procedure with a  second model. Here, for simplicity, model 2 only differs from model 1 in the prior; of course  in more interesting settings, not only the prior, but the whole architecture of models  may be different (kind of and/or number of parameters). Any models can be compared in principle;  as long as inferences are done for the same (summary) data (and simulations always match the structure of the data), distance method (here <code>abs()</code>) and  target <span>$ϵ$</span>. The same target <span>$ϵ$</span> is important in ABCdeZ.jl due to the (typically) unnormalised  ABC kernel (see box &quot;Model evidence (off by a factor)&quot; <a href="#Inference-by-abcdesmc!">here</a>; if not possible, advanced info <a href="#More-on-model-evidences">here</a>).</p><pre><code class="language-julia hljs">### model 2 inference
σ₂² = 100
prior2 = Normal(0, sqrt(σ₂²))

model2(θ) = model1(θ)

dist2!(θ, ve) = abs(model2(θ)-data), nothing

r2 = abcdesmc!(prior2, dist2!, ϵ, nothing, 
                    nparticles=1000, parallel=true)

posterior2 = [t[1] for t in r2.P[r2.Wns .&gt; 0.0]]
evidence2 = exp(r2.logZ)</code></pre><p>The posterior inference of model 2 is visually very similar to model 1, except the difference in the prior (Figure above, right panel).</p><p>Finally, the estimated evidences can be used to compute posterior model probabilities. The model prior is uniform between the two models here.</p><pre><code class="language-julia hljs">### model probabilities
# model priors (uniform here)
mprior1 = 0.5
mprior2 = 0.5

# model posterior probabilities
mposterior1 = evidence1*mprior1 / (evidence1*mprior1 + evidence2*mprior2) # posterior prob. model 1
mposterior2 = evidence2*mprior2 / (evidence1*mprior1 + evidence2*mprior2) # posterior prob. model 2</code></pre><p>The model probabilities can be visually compared (Figure below), recovering the exact analytical results. Note that evidence values by ABCdeZ.jl are numerically uncertain (see box &quot;Uncertainty of model evidence&quot; <a href="#Inference-by-abcdesmc!">here</a>); as such the figure below also shows evidence values from repeated runs.</p><img src="./assets/abcdez_min_ex_model_sel.png" width="320"><p>The complete code for this minimal example, including the derivation of the  analytical counterparts, can be found on <a href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/main/examples/minimal_example.jl">GitHub</a>.</p><div class="admonition is-info"><header class="admonition-header">Prior</header><div class="admonition-body"><p>Multidimensional prior distributions (continuous, discrete or mixed) can  be specified via the <a href="#Distributions-and-Priors"><code>Factored()</code></a> syntax (from  independent 1d marginals), e.g. <code>prior2d = Factored(Normal(0, sqrt(10)),  DiscreteUniform(1, 10))</code>.</p></div></div><h2 id="Inference-by-abcdesmc!"><a class="docs-heading-anchor" href="#Inference-by-abcdesmc!">Inference by abcdesmc!</a><a id="Inference-by-abcdesmc!-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-by-abcdesmc!" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ABCdeZ.abcdesmc!" href="#ABCdeZ.abcdesmc!"><code>ABCdeZ.abcdesmc!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">abcdesmc!(prior, dist!, ϵ_target, varexternal; &lt;keyword arguments&gt;)</code></pre><p>Run ABC with diffential evolution (de) moves in a sequential Monte Carlo setup (smc)  providing posterior samples and a model evidence estimate.</p><p>The particles have to be weighted (via <code>r.Wns</code>) for valid posterior samples.</p><p><strong>Arguments</strong></p><ul><li><code>prior</code>: <code>Distribution</code> or <code>Factored</code> object specifying the parameter prior.</li><li><code>dist!</code>: distance function computing the distance (<code>≥ 0.0</code>) between model and data,    for given <code>(θ, ve)</code> input (<code>θ</code> parameters, <code>ve</code> external variables, see <code>varexternal</code>).</li><li><code>ϵ_target</code>: final target distance (or more general, target width of the ABC kernel); algorithm    stops if <code>ϵ_target</code> or <code>nsims_max</code> is reached.</li><li><code>varexternal</code>: external variables that are passed as second positional argument to <code>dist!</code>    and can be used to support the distance computation with fast in-place operations in    a thread-safe manner; objects in <code>varexternal</code> can be in-place mutated, even in <code>parallel</code> mode,    as each thread will receive its own copy of <code>varexternal</code> (if not needed input <code>nothing</code>).</li><li><code>nparticles::Int=100</code>: number of total particles to use for inference.</li><li><code>α=0.95</code>: used for adaptive choice of ϵ specifying the sequential target distributions; technically,    ϵ will be the <code>α</code>-quantile of current particle distances.</li><li><code>δess=0.5</code>: if the fractional effective sample size drops below <code>δess</code>, a stratified resampling step is performed.</li><li><code>nsims_max::Int=10^7</code>: maximal number of <code>dist!</code> evaluations (not counting initial samples from prior);    algorithm stops if <code>ϵ_target</code> or <code>nsims_max</code> is reached.</li><li><code>Kmcmc::Int=3</code>: number of MCMC (Markov chain Monte Carlo) steps at each sequential    target distribution specified by current ϵ and ABC kernel type.</li><li><code>ABCk=ABCdeZ.Indicator0toϵ</code>: ABC kernel to be specified by ϵ widths that receives distance values.</li><li><code>facc_min=0.25</code>: if the fraction of accepted MCMC proposals drops below <code>facc_min</code>, diffential evolution    proposals are reduced by a factor of <code>facc_tune</code>.</li><li><code>facc_tune=0.95</code>: factor to reduce the jump distance of the diffential evolution    proposals in the MCMC step (used if <code>facc_min</code> is reached).</li><li><code>verbose::Bool=true</code>: if set to <code>true</code>, enables verbosity (printout to REPL).</li><li><code>verboseout::Bool=true</code>: if set to <code>true</code>, algorithm returns a more detailed inference output.</li><li><code>rng=Random.GLOBAL_RNG</code>: an AbstractRNG object which is used by the inference.</li><li><code>parallel::Bool=false</code>: if set to <code>true</code>, threaded parallelism is enabled; <code>dist!</code> must be    thread-safe in such a case, e.g. by making use of <code>varexternal</code> (<code>ve</code>).</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ABCdeZ, Distributions;
julia&gt; data = 5;
julia&gt; prior = Normal(0, sqrt(10));
julia&gt; model(θ) = rand(Normal(θ, 1));
julia&gt; dist!(θ, ve) = abs(model(θ)-data), nothing;
julia&gt; ϵ = 0.3;
julia&gt; r = abcdesmc!(prior, dist!, ϵ, nothing, nparticles=1000, parallel=true);
julia&gt; posterior = [t[1] for t in r.P[r.Wns .&gt; 0.0]];
julia&gt; evidence = exp(r.logZ);</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_smc.jl#L161-L210">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Posterior sample weights</header><div class="admonition-body"><p>Posterior samples obtained by <code>abcdesmc!</code> have to be associated with their weights (<code>r.Wns</code>).  With an indicator ABC kernel (default) there are just two weights (i.e. alive and dead  particles) and the correct posterior samples are hence given by  <code>posterior = [t[1] for t in r.P[r.Wns .&gt; 0.0]]</code> (for the first parameter here).</p></div></div><div class="admonition is-warning"><header class="admonition-header">Model evidence (off by a factor)</header><div class="admonition-body"><p>The model evidence estimates from the <code>abcdesmc!</code> method obtained by the default ABC  indicator kernel are off by a normalisation factor coming from an unnormalised  kernel (the one used in the final iteration). To do model selection / comparison  this means that evidence estimates for the set of models have to be done for the same  data (or summary statistics), distance function, ABC kernel <em>and</em> the same target  ϵ (which is <code>ϵ_target</code> if run not stopped by <code>nsims_max</code>). Then the (unknown)  normalisation factor is the same for all models and does not matter (cancels) for  Bayes factors or posterior model probabilities. See <a href="#More-on-model-evidences">here</a> for workarounds if ϵ is not the same.</p></div></div><div class="admonition is-success"><header class="admonition-header">Uncertainty of model evidence</header><div class="admonition-body"><p>As of now the <code>abcdesmc!</code> method does not provide a (numerical) uncertainty for the model evidence  estimate from a single run. It may be however very useful to check for this when doing  model comparison (as the resulting Bayes factors or posterior model probabilities are  uncertain as well). So, if the runtime permits, run the <code>abcdesmc!</code> method multiple times  and collect the resulting set of evidence values for <code>mean</code>/<code>median</code> and <code>std</code> estimates.</p></div></div><h2 id="Inference-by-abcdemc!"><a class="docs-heading-anchor" href="#Inference-by-abcdemc!">Inference by abcdemc!</a><a id="Inference-by-abcdemc!-1"></a><a class="docs-heading-anchor-permalink" href="#Inference-by-abcdemc!" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ABCdeZ.abcdemc!" href="#ABCdeZ.abcdemc!"><code>ABCdeZ.abcdemc!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">abcdemc!(prior, dist!, ϵ_target, varexternal; &lt;keyword arguments&gt;)</code></pre><p>Run ABC with diffential evolution (de) moves in a Markov chain Monte Carlo setup (mc)  providing posterior samples.</p><p>Algorithm needs to converge for an unbiased posterior estimate.</p><p><strong>Arguments</strong></p><ul><li><code>prior</code>: <code>Distribution</code> or <code>Factored</code> object specifying the parameter prior.</li><li><code>dist!</code>: distance function computing the distance (<code>≥ 0.0</code>) between model and data,    for given <code>(θ, ve)</code> input (<code>θ</code> parameters, <code>ve</code> external variables, see <code>varexternal</code>).</li><li><code>ϵ_target</code>: final target distance (or more general, target width of the ABC kernel); algorithm    equilibrates to final target distribution (approximate posterior) if <code>ϵ_target</code> is reached.</li><li><code>varexternal</code>: external variables that are passed as second positional argument to <code>dist!</code>    and can be used to support the distance computation with fast in-place operations in    a thread-safe manner; objects in <code>varexternal</code> can be in-place mutated, even in <code>parallel</code> mode,    as each thread will receive its own copy of <code>varexternal</code> (if not needed input <code>nothing</code>).</li><li><code>nparticles::Int=50</code>: number of total particles to use for inference in each generation.</li><li><code>generations::Int=20</code>: number of generations (total iterations) to run the algorithm.</li><li><code>verbose::Bool=true</code>: if set to <code>true</code>, enables verbosity (printout to REPL).</li><li><code>rng=Random.GLOBAL_RNG</code>: an AbstractRNG object which is used by the inference.</li><li><code>parallel::Bool=false</code>: if set to <code>true</code>, threaded parallelism is enabled; <code>dist!</code> must be    thread-safe in such a case, e.g. by making use of <code>varexternal</code> (<code>ve</code>).</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ABCdeZ, Distributions;
julia&gt; data = 5;
julia&gt; prior = Normal(0, sqrt(10));
julia&gt; model(θ) = rand(Normal(θ, 1));
julia&gt; dist!(θ, ve) = abs(model(θ)-data), nothing;
julia&gt; ϵ = 0.3;
julia&gt; r = abcdemc!(prior, dist!, ϵ, nothing, nparticles=1000, generations=300, parallel=true);
julia&gt; posterior = [t[1] for t in r.P];</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_mc.jl#L66-L102">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Greediness of abcdemc!</header><div class="admonition-body"><p>The <code>abcdemc!</code> method implements a &quot;greedy&quot;/biased Metropolis-Hasting step in the  Markov chain. This allows a fast convergence, particularly well-suited for unimodal  problems. However, to obtain valid posterior estimates the algorithm needs to  converge (all particles below <code>ϵ_target</code> and <code>r.reached_ϵ==true</code>). Otherwise the samples will be  biased (closer to the MAP (maximum a posteriori probability) parameter values  with reduced variation).</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In contrast to the <code>abcdesmc!</code> method the resulting posterior samples of the <code>abcdemc!</code>  method are <em>not</em> associated with weights and can be used directly, i.e.  <code>posterior = [t[1] for t in r.P]</code> (for the first parameter here).</p></div></div><h2 id="Distributions-and-Priors"><a class="docs-heading-anchor" href="#Distributions-and-Priors">Distributions and Priors</a><a id="Distributions-and-Priors-1"></a><a class="docs-heading-anchor-permalink" href="#Distributions-and-Priors" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ABCdeZ.Factored" href="#ABCdeZ.Factored"><code>ABCdeZ.Factored</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Factored{N} &lt;: Distribution{Multivariate, MixedSupport}</code></pre><p>A <code>Distribution</code> type that can be used to combine multiple <code>UnivariateDistribution</code>&#39;s (independently).</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; prior = Factored(Normal(0, 1), Uniform(-1, 1))
Factored{2}(
p: (Normal{Float64}(μ=0.0, σ=1.0), Uniform{Float64}(a=-1.0, b=1.0))
)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_priors.jl#L5-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.pdf" href="#Distributions.pdf"><code>Distributions.pdf</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">pdf(d::Factored, x)</code></pre><p>Function to evaluate the pdf of a <code>Factored</code> distribution object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_priors.jl#L22-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.logpdf" href="#Distributions.logpdf"><code>Distributions.logpdf</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">logpdf(d::Factored, x)</code></pre><p>Function to evaluate the logpdf of a <code>Factored</code> distribution object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_priors.jl#L35-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.rand" href="#Base.rand"><code>Base.rand</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">rand(rng::AbstractRNG, factoreddist::Factored)</code></pre><p>Function to sample one element from a <code>Factored</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_priors.jl#L48-L52">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.length" href="#Base.length"><code>Base.length</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">length(p::Factored)</code></pre><p>Returns the number of distributions contained in <code>p</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mauricelanghinrichs/ABCdeZ.jl/blob/d5d6289660f40d3bb41f802d684adf1b62a39e57/src/abcdez_priors.jl#L56-L60">source</a></section></article><h2 id="Various-notes"><a class="docs-heading-anchor" href="#Various-notes">Various notes</a><a id="Various-notes-1"></a><a class="docs-heading-anchor-permalink" href="#Various-notes" title="Permalink"></a></h2><h4 id="ABC-Approximations"><a class="docs-heading-anchor" href="#ABC-Approximations">ABC - Approximations</a><a id="ABC-Approximations-1"></a><a class="docs-heading-anchor-permalink" href="#ABC-Approximations" title="Permalink"></a></h4><p>eps, summary stats</p><p>ABC (kernel instead of likelihood) and summary stats both introduce approximation errors, maybe read the  two lines in Didelot again...</p><p>eps trade off</p><h4 id="More-on-model-evidences"><a class="docs-heading-anchor" href="#More-on-model-evidences">More on model evidences</a><a id="More-on-model-evidences-1"></a><a class="docs-heading-anchor-permalink" href="#More-on-model-evidences" title="Permalink"></a></h4><p>when using summary stats =&gt; <em>sufficient</em> for model selection (link stackoverflow post and paper)</p><p>summary stats need to be sufficient for model selection        (it is not enough if summary stats are sufficient for         each model&#39;s parameters!), link to paper and         stackoverflow topic</p><p>\@ref(normalisation_factor) off by normalisation factor (with default kernel), does not  matter when comparing models for the same eps;  what if same eps not available / impractical?</p><p>same ϵ target necessary (if not possible upper bound conservative        estimate may be possible, or, use ϵs and logZs lists for finding        last common ϵ to compare with)</p><p>explain here what to do when same eps difficult (link goes here...)</p><h4 id="Features-for-the-distance-methods"><a class="docs-heading-anchor" href="#Features-for-the-distance-methods">Features for the distance methods</a><a id="Features-for-the-distance-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Features-for-the-distance-methods" title="Permalink"></a></h4><ul><li><p>In the distance function in the <a href="#Minimal-example">minimal example</a> (<code>dist!(θ, ve) = abs(model(θ)-data), nothing</code>)  <code>ve</code> are &quot;external variables&quot; (<code>varexternal</code> in <code>abcdesmc!</code>) that can  be used in the distance computation and mutated in-place, even in the parallel mode  (each thread will obtain its own copy for thread-safe parallel ABC runs). <code>ve</code> is passed as 4th positional argument to <code>abcdesmc!</code> (<code>nothing</code> in the  minimal example).</p></li><li><p>In the distance function in the <a href="#Minimal-example">minimal example</a> (<code>dist!(θ, ve) = abs(model(θ)-data), nothing</code>)  the second return argument (<code>nothing</code>) can be used to store arbitrary data  (<code>blobs</code>) to each particle; these <code>blobs</code> will be associated with the final  posterior samples/particles in the end. For example <code>blobs</code> could record the  actual simulation output:</p><pre><code class="language-julia hljs">function dist2!(θ, ve, constants, data)
    # constants can be used to pass thread-safe constants that are NOT mutated;
    # ve for in-place, mutatable variables

    # distance method
    simdata = model(θ)
    blob = simdata
    d = abs(simdata-data)
    d, blob
end
dist2!(θ, ve) = dist2!(θ, ve, nothing, data)

r = abcdesmc!(prior, dist2!, ϵ, nothing, 
                    nparticles=1000, parallel=true)

posterior = [t[1] for t in r.P[r.Wns .&gt; 0.0]]
evidence = exp(r.logZ)
blobs = r.blobs[r.Wns .&gt; 0.0]</code></pre></li></ul><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>Some part of the code was copied, adapted and/or inspired by KissABC.jl <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>. For example,    the <code>Factored</code> syntax was adopted, <code>abcdemc!</code> is based on <code>ABCDE</code>, <code>abcdesmc!</code> is loosely based on    <code>smc</code>. We thank the developers of the package.</li><li>A very good theory background for the general approach of model evidences from single ABC runs    is given by Didelot et al. (2011) <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup>. More details on algorithms (in the likelihood-context) is found in Llorente et al. (2020) <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup>.</li><li>The differential evolution moves are introduced in Ter Braak (2006) <sup class="footnote-reference"><a id="citeref-4" href="#footnote-4">[4]</a></sup>.</li><li>As done also in KissABC.jl <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, the implementations of the <code>abcdemc!</code> method are a simplified    version of the method in Turner et al. (2012) <sup class="footnote-reference"><a id="citeref-5" href="#footnote-5">[5]</a></sup>. The algorithmic idea in <code>abcdesmc!</code> is mostly based on Amaya et al. (2021) <sup class="footnote-reference"><a id="citeref-6" href="#footnote-6">[6]</a></sup>,   next to KissABC.jl, particular the handling of weights and the adaptive differential evolution move tuning (Amaya et al. (2021) is    in the likelihood context, which we adapted to ABC).</li><li>Closer read on sufficient summary statistics for model comparison in ABC is found in Marin et al. (2014) <sup class="footnote-reference"><a id="citeref-7" href="#footnote-7">[7]</a></sup> and condensed in this    stackexchange post <sup class="footnote-reference"><a id="citeref-8" href="#footnote-8">[8]</a></sup>.</li><li>Stratified resampling (for <code>abcdesmc!</code>) is inspired by Douc et al. (2005) <sup class="footnote-reference"><a id="citeref-9" href="#footnote-9">[9]</a></sup>.</li></ul><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#ABCdeZ.Factored"><code>ABCdeZ.Factored</code></a></li><li><a href="#ABCdeZ.abcdemc!"><code>ABCdeZ.abcdemc!</code></a></li><li><a href="#ABCdeZ.abcdesmc!"><code>ABCdeZ.abcdesmc!</code></a></li><li><a href="#Base.length"><code>Base.length</code></a></li><li><a href="#Base.rand"><code>Base.rand</code></a></li><li><a href="#Distributions.logpdf"><code>Distributions.logpdf</code></a></li><li><a href="#Distributions.pdf"><code>Distributions.pdf</code></a></li></ul><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a><a href="https://github.com/francescoalemanno/KissABC.jl">KissABC (https://github.com/francescoalemanno/KissABC.jl)</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a><a href="https://doi.org/10.1214/11-BA602">Didelot et al. &quot;Likelihood-free estimation of model evidence.&quot; Bayesian Anal. 6 (1) 49 - 76, 2011.</a></li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a><a href="https://arxiv.org/abs/2005.08334">Llorente et al. &quot;Marginal likelihood computation for model selection and hypothesis testing: an extensive review&quot; arXiv:2005.08334 [stat.CO], 2020.</a></li><li class="footnote" id="footnote-4"><a class="tag is-link" href="#citeref-4">4</a><a href="https://link.springer.com/article/10.1007/s11222-006-8769-1">Ter Braak. &quot;A Markov Chain Monte Carlo version of the genetic algorithm Differential Evolution: easy Bayesian computing for real parameter spaces&quot; Statistics and Computing volume 16, pages 239–249, 2006.</a></li><li class="footnote" id="footnote-5"><a class="tag is-link" href="#citeref-5">5</a><a href="https://compmem.org/assets/pubs/Turner.Sederberg.2012.pdf">Turner et al. &quot;Approximate Bayesian computation with differential evolution&quot;  Journal of Mathematical Psychology, 2012.</a></li><li class="footnote" id="footnote-6"><a class="tag is-link" href="#citeref-6">6</a><a href="https://arxiv.org/abs/2105.02012">Amaya et al. &quot;Adaptive sequential Monte Carlo for posterior inference and model selection among complex geological priors&quot; arXiv:2105.02012 [physics.geo-ph], 2021.</a></li><li class="footnote" id="footnote-7"><a class="tag is-link" href="#citeref-7">7</a><a href="https://www.jstor.org/stable/24774605">Marin et al. &quot;Relevant statistics for Bayesian model choice&quot; J. R. Statist. Soc. B, 2014.</a></li><li class="footnote" id="footnote-8"><a class="tag is-link" href="#citeref-8">8</a><a href="https://stats.stackexchange.com/questions/26980/abc-model-selection">https://stats.stackexchange.com/questions/26980/abc-model-selection</a></li><li class="footnote" id="footnote-9"><a class="tag is-link" href="#citeref-9">9</a><a href="https://arxiv.org/abs/cs/0507025">Douc et al. &quot;Comparison of Resampling Schemes for Particle Filtering&quot; arXiv:cs/0507025 [cs.CE], 2005.</a></li></ul></section></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 4 April 2023 08:26">Tuesday 4 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
